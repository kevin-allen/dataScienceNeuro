{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c73fdbd-2182-4cd1-889d-de779af5b641",
   "metadata": {},
   "source": [
    "# Hands-on week 2, Data science in Neuroscience\n",
    "\n",
    "You can download this Notebook from https://github.com/kevin-allen/dataScienceNeuro\n",
    "\n",
    "\n",
    "## Plan for today\n",
    "\n",
    "1. Review our machine example so far\n",
    "2. Measuring model performance\n",
    "3. Gradient descent\n",
    "4. Training loop\n",
    "5. Exercise\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc23ecc6-ca8b-419d-86bb-f0e2b6e675a8",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "### Simulation of our speed cell\n",
    "\n",
    "Yesterday, we started to work with our linear regression model. \n",
    "\n",
    "For a linear regression, the model is $Y = Xw + b$\n",
    "\n",
    "In machine learning lingo, $w$ is the weight, and $b$ is the bias.\n",
    "\n",
    "Our formula for simulating the firing rate is\n",
    "\n",
    "$rate = speed*w + b + error$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f19d082-aa1e-46c1-96ec-c5e7ac3bbf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace34bc7-0ccd-47cf-a059-63c8537ef1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"../data/animal_speed.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "376713f5-ef6d-49bb-bf86-54e92fa094b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = np.load(fn)\n",
    "\n",
    "w = 1.25 # parameter 2\n",
    "b = 10 # parameter 1\n",
    "np.random.seed(0)\n",
    "e = np.random.normal(loc=0.0, scale=5, size = speed.shape[0]) # random numbers taken from a normal distribution\n",
    "\n",
    "rate = speed * w + b + e\n",
    "rate = np.maximum(0, rate) # eliminate the negative firing rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bbce23a-c145-4f25-92be-d6e69ba64f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.82026173, 2.00078604, 4.89368992, ..., 2.11282899, 7.93865769,\n",
       "       5.00526146])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7390e49-7f5d-4b53-91b4-5ef26d170055",
   "metadata": {},
   "source": [
    "### Model prediction with matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08b62b9-08a4-4260-9a17-289ffd66eff7",
   "metadata": {},
   "source": [
    "We used matrix multiplication to make predictions with our model. \n",
    "\n",
    "* We created a matrix with our model coefficients (1,2)\n",
    "* We created a matrix with our speed data (2x27304)\n",
    "\n",
    "\n",
    "$ \\begin{bmatrix} b & w \\end{bmatrix} * \\begin{bmatrix} 1 & 1 & 1 & 1 \\\\ speed_0 & speed_1 & speed_2 & speed_3 \\end{bmatrix} = \\begin{bmatrix} y_0 & y_1 & y_2 & y_3 \\end{bmatrix}$\n",
    "\n",
    "\n",
    "Each element of y results from $b*1+w*speed$, which is our linear model.\n",
    "\n",
    "* The multiplication gives a matrix of shape (1,27304). This matrix contains the prediction of the model for 27304 data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50160f69-6dc4-4a0d-8b90-6ce1410b02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.array([[0.0,3.0]]) # random guess of the 2 model parameters, same as above\n",
    "X = np.ones((2,speed.shape[0]))  # make a 2 rows array with ones in the first row and speed in the second row\n",
    "X[1,:] = speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afb32e7-e0e1-4988-83b6-4864dffe156b",
   "metadata": {},
   "source": [
    "Model prediction using $theta@X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b8f4b02-7de0-490c-983e-cb5e1493da46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2), (2, 27304))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6225d8fb-779b-452b-8f05-c543f45e9b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = theta@X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7884132-157c-4166-95fe-d8cc955604bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49.68329766, 55.18778178, 44.91174883, ..., 80.04574821,\n",
       "        79.2355093 , 78.89726005]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42a3376f-e084-4a88-bf99-bff9dad3021f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39.52163576, 34.99569512, 33.6069186 , ..., 45.46522408,\n",
       "       50.95345323, 47.87911982])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cf63b05-44bf-41bc-8175-e0038b9c065c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 27304)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a22640-8fab-4ff7-bd41-43b9b3bc23e8",
   "metadata": {},
   "source": [
    "## Measuring model performance\n",
    "\n",
    "To be able to train any model, you need a measure of how bad it is doing it is doing. This is usually refer to as a `loss function`.\n",
    "\n",
    "For linear regression model, the mean squared error (MSE) is often used. \n",
    "\n",
    "\n",
    "$MSE = \\frac{1}{m} \\sum_{i = 1}^{m}(\\hat{y}^{i} - y^{i})^2$, where\n",
    "\n",
    "* $m$ is the number of data points\n",
    "* $y$ is the measured dependent variable (firing rate of the neuron) \n",
    "* $\\hat{y}$ is the prediction of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d21d7-3ecf-49c8-8f89-c8b1ec80d5cc",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Calculate the mean squared error (MSE) for our untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e4b87e3-324b-45e3-8f88-6dc7bfd9adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = yhat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd5b0bfe-6a22-4e78-bebe-9a20409a7dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457.7375553920619"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1/m) * np.sum((yhat-rate)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90a69a5f-7fa5-49ac-b73c-e07bc1782ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457.7375553920619"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((yhat-rate)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296b0b2-284b-4959-b1df-f47248dae879",
   "metadata": {},
   "source": [
    "The task of the training loop (machine learning) in this exercise is to modify the model parameters to reduce the MSE to the smallest value possible.\n",
    "\n",
    "## Training procedure using gradient descent\n",
    "\n",
    "We want to tweak the parameters with the goal of reducing the MSE. \n",
    "\n",
    "One way to do this is to use an optimization algorithm called **gradient descent**. \n",
    "\n",
    "Gradient descent is capable of finding optimal solutions to many type of problems/functions.\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"../images/gradient_descent.png\" width=\"1000\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c312f6e6-8ed9-4732-8c4c-537f167988ac",
   "metadata": {},
   "source": [
    "With gradient descent, we calculate the slope of the loss function with the current parameters, then we change the parameters so that we move down the slope. \n",
    "\n",
    "The amount by which we move down the slope is controlled by a model hyperparameter called `learning rate`.\n",
    "\n",
    "The model hyperparameters are not optimized from the data. They control how the model learns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f6bde5-7b18-46d7-b064-991417e24a0e",
   "metadata": {},
   "source": [
    "We can have a look at the cost function as a function of different values of $\\theta_1$ or $w$. This is the slope of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "030e9e5c-3891-4a28-9467-83d4f3fad7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27304,)\n",
      "(1, 27304)\n"
     ]
    }
   ],
   "source": [
    "print(rate.shape)\n",
    "rateM = np.expand_dims(rate,0) # creating a matrix with one row and 27304 column, just like yhat.\n",
    "print(rateM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ad824c2-dbeb-4b89-942c-c78b74eeb98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.array([[10.0,2.0]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b2b4927-d36f-4ade-9cd4-3279808485f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2), (2, 27304))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42d88037-893b-47e1-b3d1-73cc959e959c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nDataPoints=200\n",
    "theta[0,0]=10.0 # I am cheating and set b to the correct value to see if the loss function will have a minimum at the correct value of w\n",
    "\n",
    "res = np.empty(nDataPoints)\n",
    "param_values = np.linspace(-5.0,7.5,nDataPoints)\n",
    "for i,t in enumerate(param_values):\n",
    "    theta[0,1]=t # change the second parameter of the model\n",
    "    res[i] = np.mean((rateM-theta@X)**2)\n",
    "plt.plot(param_values,res)\n",
    "plt.xlabel(r\"$\\theta_1$\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(r\"Loss as a function of $\\theta_0$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaf8ccc-39e5-4674-ab7f-ee2ab9035f1b",
   "metadata": {},
   "source": [
    "### Partial derivative of the cost function\n",
    "\n",
    "To be able to adjust the parameters in the right direction, we need to know the slope for a specific value of $\\theta$.\n",
    "\n",
    "This is called the partial derivative for our parameters.\n",
    "\n",
    "For the case of the MSE, the formula for the partial derivative is:\n",
    "\n",
    "$\\nabla_{\\theta}MSE(\\theta) = \\frac{2}{m} (\\theta X - y)X^{T}$\n",
    "\n",
    "* $y$ is your fiirng rate.\n",
    "* $X^{T}$ is the transpose of $X$. In NumPy, this is `X.T`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec23bccc-1e04-4ef2-9bb0-8d50a3f14ac3",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Write the code that will give you the partial derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18f94671-2b93-41ec-aa79-9e1a3f6f3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.array([[10,2]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65f5e4d2-7708-477c-80db-4300bc975d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43.12219844, 46.79185452, 39.94116588, ..., 63.36383214,\n",
       "        62.82367287, 62.59817337]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta@X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a829fc3-e344-430e-aba1-b4b7991e9a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [16.56109922, 18.39592726, 14.97058294, ..., 26.68191607,\n",
       "        26.41183643, 26.29908668]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "304c0f36-71c4-4d33-a5e0-60d6aa96208c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 16.66258499, 353.46724317]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2/m)*(theta@X - rate) @ X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858aab75-08a6-4b79-a0c5-25aa16504a8f",
   "metadata": {},
   "source": [
    "In the training loop, negative gradients mean that you increase the values of the coefficients to reduce the MSE.\n",
    "\n",
    "Because we use all observations to calculate the gradients, this is called **batch gradient descent**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7514fc6-cd42-4717-8a9d-aac8fb06cfe6",
   "metadata": {},
   "source": [
    "For more complex models, you can use [pytorch](https://pytorch.org/) to calculate the derivative for you automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30d7e5-e986-474a-8a5f-1511fca4be9a",
   "metadata": {},
   "source": [
    "### Our first training loop\n",
    "\n",
    "This is a simple training loop. We loop several times and make small adjustments to the coefficients on each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f093ac0-4f91-4f0f-989d-f8259f4d9f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta at start: [[20. -2.]]\n",
      "iteration:0, gradients: [[  -52.12155036 -1312.69499501]]\n",
      "iteration:1, gradients: [[  6.3601809 -71.1166835]]\n",
      "iteration:2, gradients: [[ 9.4917568  -4.26051724]]\n",
      "iteration:3, gradients: [[ 9.64292294 -0.65968656]]\n",
      "iteration:4, gradients: [[ 9.6336361 -0.4649713]]\n",
      "iteration:5, gradients: [[ 9.61574259 -0.45366692]]\n",
      "iteration:6, gradients: [[ 9.59741884 -0.45224024]]\n",
      "iteration:7, gradients: [[ 9.57910504 -0.451347  ]]\n",
      "iteration:8, gradients: [[ 9.56082485 -0.45048405]]\n",
      "iteration:9, gradients: [[ 9.54257947 -0.44962428]]\n",
      "iteration:1000, gradients: [[ 1.43732497 -0.06772343]]\n",
      "iteration:2000, gradients: [[ 0.21280311 -0.01002679]]\n",
      "iteration:3000, gradients: [[ 0.03150656 -0.00148452]]\n",
      "iteration:4000, gradients: [[ 0.0046647  -0.00021979]]\n",
      "iteration:5000, gradients: [[ 6.90632390e-04 -3.25410011e-05]]\n",
      "optimized theta: [[9.95650957 1.25322235]]\n"
     ]
    }
   ],
   "source": [
    "lr = 0.002 # learning rate\n",
    "n_iterations = 6000 \n",
    "m = rate.shape[0] # number of data points\n",
    "\n",
    "#theta = np.random.rand(2) # set random parameters as a starting point\n",
    "theta = np.array([[20.0,-2.0]]) \n",
    "print(\"theta at start:\", theta)\n",
    "\n",
    "# learning loop\n",
    "for iteration in range(n_iterations):\n",
    "\n",
    "    \n",
    "    # make a prediction by feeding data to our model\n",
    "    yhat = theta@X\n",
    "    \n",
    "    # calculate the gradients with the current parameters\n",
    "    gradients = 2/m *(yhat - rateM) @ X.T\n",
    "    \n",
    "    # adjust the parameter so that we reduce the MSE\n",
    "    theta = theta - lr * gradients\n",
    "\n",
    "    if iteration%1000 == 0 or iteration<10:  # some information\n",
    "        print(\"iteration:{}, gradients: {}\".format(iteration,gradients))\n",
    "\n",
    "print(\"optimized theta:\",theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91c0a0a-4db8-41c1-b711-7fd359de6b3f",
   "metadata": {},
   "source": [
    "## Exercise: \n",
    "\n",
    "* Use our optimized model to make rate predictions \n",
    "* Plot the predicted and observed firing rates as a function of running speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5c3272-98ef-4610-940e-3d2aba197e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d403a5a7-c3af-4bb4-834a-f376708d8189",
   "metadata": {},
   "source": [
    "### Visualisation of the training process\n",
    "\n",
    "Here I created a small animation to visualize the training process. \n",
    "\n",
    "Don't worry about all the details relating to plotting the data. The training process is exactly the same as above. \n",
    "\n",
    "We save training parameters $w$ and $b$, the MSE and the gradients in numpy arrays at each iteration, and use this data to generate a plot for each iteration. We then put all images together to create an animation.\n",
    "\n",
    "The code takes approximately a minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77c801c7-da10-4ddf-b13a-51ca0004f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9542c67-9c29-4e1c-8ec4-4a3377845b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized theta: [[9.89349625 1.2561914 ]]\n"
     ]
    }
   ],
   "source": [
    "lr = 0.002\n",
    "n_epochs = 3000 # how many time we go through the data during the learning process, one epoch = one pass through the data.\n",
    "m = rate.shape[0]\n",
    "theta = np.array([[-10,-10]])\n",
    "\n",
    "# variables for our animation\n",
    "animation_dir = \"../images/learning_animation/\"\n",
    "imageFileNames = []\n",
    "save_every = 25\n",
    "\n",
    "# arrays to store the results at each iteration\n",
    "mseLearning = np.empty(n_epochs)\n",
    "tLearning = np.empty((n_epochs,2))\n",
    "gradLearning = np.empty((n_epochs,2))\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    gradients = 2/m *(theta@X - rateM) @ X.T\n",
    "    \n",
    "    # save results for the animation\n",
    "    mseLearning[epoch] = np.mean((rate-theta@X)**2)\n",
    "    tLearning[epoch,:] = theta\n",
    "    gradLearning[epoch,:] = gradients\n",
    "    \n",
    "    \n",
    "    # change the parameters\n",
    "    theta = theta - lr * gradients\n",
    "    \n",
    "    \n",
    "    # make one figure for our animation\n",
    "\n",
    "    if epoch < 5 or epoch % save_every == 0:\n",
    "        fn = os.path.join(animation_dir,\"image_{}.png\".format(epoch))\n",
    "        imageFileNames.append(fn)\n",
    "        fig, ax = plt.subplots(1,4,figsize=(13,3),layout=\"constrained\")\n",
    "    \n",
    "        # plot the MSE\n",
    "        ax[0].plot(np.arange(epoch),mseLearning[:epoch])\n",
    "        ax[0].set_xlim(0,n_epochs)\n",
    "        ax[0].set_ylim(0,200)\n",
    "        ax[0].set_xlabel(\"Epochs\")\n",
    "        ax[0].set_ylabel(\"Loss (MSE)\")\n",
    "        ax[0].spines['top'].set_visible(False)\n",
    "        ax[0].spines['right'].set_visible(False) \n",
    "        ax[0].set_title(\"MSE\")\n",
    "        \n",
    "        # plot the gradients\n",
    "        ax[1].plot(np.arange(epoch),gradLearning[:epoch,1],label=\"$w$ gradient\")\n",
    "        ax[1].plot(np.arange(epoch),gradLearning[:epoch,0],label=\"$b$ gradient\")\n",
    "        ax[1].set_xlim(0,n_epochs)\n",
    "        ax[1].set_ylim(-10,1)\n",
    "        ax[1].set_xlabel(\"Epochs\")\n",
    "        ax[1].set_ylabel(\"Gradients\")\n",
    "        ax[1].legend(loc=4)\n",
    "        ax[1].spines['top'].set_visible(False)\n",
    "        ax[1].spines['right'].set_visible(False) \n",
    "        ax[1].set_title(\"Gradients\")\n",
    "    \n",
    "        # plot the parameters\n",
    "        ax[2].scatter(tLearning[:epoch,0],tLearning[:epoch,1],color=\"gray\",s=3,alpha=0.5)\n",
    "        ax[2].scatter(tLearning[epoch,0],tLearning[epoch,1],color=\"red\",s=5)\n",
    "        ax[2].set_xlim(-10,12)\n",
    "        ax[2].set_ylim(-0.5,3)\n",
    "        ax[2].set_xlabel(\"$b$\")\n",
    "        ax[2].set_ylabel(\"$w$\")\n",
    "        ax[2].text(-0.5, 2.5, \"Epoch {}/{}\".format(epoch,n_epochs))\n",
    "        ax[2].spines['top'].set_visible(False)\n",
    "        ax[2].spines['right'].set_visible(False)\n",
    "        ax[2].set_title(\"Parameters\")\n",
    "    \n",
    "        # plot the data and regression line\n",
    "        x=np.arange(70)\n",
    "        y = x*theta[0,1] + theta[0,0]\n",
    "        \n",
    "        \n",
    "        ax[3].scatter(speed[::10],rate[::10],label=\"Data\",alpha=0.5,s=1) # only plot every 10 data points to speed up plot function\n",
    "        ax[3].plot(x,y,label=\"Model\",color=\"red\")\n",
    "        ax[3].set_xlabel(\"Speed (cm/sec)\")\n",
    "        ax[3].set_ylabel(\"Firing rate (Hz)\")\n",
    "        ax[3].set_xlim(0,70)\n",
    "        ax[3].set_ylim(-10,130)\n",
    "        ax[3].legend(loc=4)\n",
    "        ax[3].set_title(\"Data and Model\")\n",
    "        ax[3].spines['top'].set_visible(False)\n",
    "        ax[3].spines['right'].set_visible(False)\n",
    "        \n",
    "        plt.savefig(fn)\n",
    "        plt.close()\n",
    " \n",
    "print(\"optimized theta:\",theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f11fe-e9d2-47ff-8160-0276eb47d1cc",
   "metadata": {},
   "source": [
    "We can make the animation from our saved image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e5db3a8-034e-4bf1-85bc-84e64460d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(animation_dir,\"learning_animation.gif\")\n",
    "with imageio.get_writer(fn, mode='I',loop=0) as writer:\n",
    "    for filename in imageFileNames:\n",
    "        image = imageio.v2.imread(filename)\n",
    "        writer.append_data(image)\n",
    "# Remove files\n",
    "for filename in set(imageFileNames):\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367b05e7-d4c0-45c1-90f1-342c51231525",
   "metadata": {},
   "source": [
    "<img src=\"../images/learning_animation/learning_animation.gif\" width=\"1000\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88e32b4-ae4f-437d-aff8-4d441a1669aa",
   "metadata": {},
   "source": [
    "## Alternative ways to find the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d705b97c-484e-4ff1-8576-4948098788c6",
   "metadata": {},
   "source": [
    "### sklearn.linear_model.LinearRegression\n",
    "\n",
    "Scikit-Learn had built in classes to train linear and non-linear regression models. \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0be208d4-7e6a-470b-80a8-1699fbc86387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.021477375759808, array([0.        , 1.25062161]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X.T,rate)\n",
    "lin_reg.intercept_,lin_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9001bd-74c6-4bd8-bf22-cc40ac61d8a5",
   "metadata": {},
   "source": [
    "### pytorch\n",
    "\n",
    "pytorch is a platform use principally to train deep neural network. \n",
    "\n",
    "With pytorch, we need to put our data and model in torch.tensor objects instead of NumPy array. They work similarly for the most part. \n",
    "\n",
    "pytorch can calculate the derivative for you. The computations can be sent to the GPU if needed (not implemented here)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "01be8e79-b15e-45ca-bab4-e73506997842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta at start: tensor([[20., -2.]], requires_grad=True)\n",
      "loss: tensor(1898.0017, grad_fn=<MeanBackward0>)\n",
      "gradients:  tensor([[  -52.1216, -1312.6951]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# linear model making prediction\n",
    "def model(X,theta):\n",
    "    return theta@X\n",
    "# loss function returning MSE\n",
    "def loss_fn(y,yhat):\n",
    "    squared_diff = (y-yhat)**2\n",
    "    return squared_diff.mean()\n",
    "\n",
    "# model parameters stored as a pytorch tensor. This makes the calculation of the gradients possible\n",
    "theta = torch.tensor([[20.0,-2.0]],requires_grad =True)\n",
    "print(\"theta at start:\", theta)\n",
    "\n",
    "# We transform our data from NumPy array to Pytorch tensors. There is no need for gradients\n",
    "XTensor = torch.tensor(X,dtype=torch.float32)\n",
    "rateTensor= torch.tensor(rate,dtype=torch.float32)\n",
    "\n",
    "# let's run the model once and calculate the loss\n",
    "yhat = model(XTensor,theta)\n",
    "loss = loss_fn(yhat,rateTensor)\n",
    "print(\"loss:\",loss)\n",
    "loss.backward()\n",
    "\n",
    "print(\"gradients: \",theta.grad)\n",
    "\n",
    "# We need to zero the gradients; otherwise, they accumulate\n",
    "theta.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c3893e0c-f83d-4123-8ed4-b83c5885caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training loop that will modify our parameters to minimize the loss function (MSE)\n",
    "def training_loop(n_epochs, learning_rate, theta, XTensor,rateTensor):\n",
    "    for epoch in range (n_epochs):\n",
    "\n",
    "        if theta.grad is not None:\n",
    "            theta.grad.zero_() \n",
    "        \n",
    "        yhat = model(XTensor,theta)\n",
    "        loss = loss_fn(yhat,rateTensor)\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            theta -= learning_rate * theta.grad\n",
    "        \n",
    "        if epoch % 1000 ==0 or epoch < 10:\n",
    "            print(\"Epoch: {}, Loss: {}, theta: {}, Gradients: {}\".format(epoch,loss, theta, theta.grad))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed7edf27-8242-46a1-96e4-8d6d8ddea35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1898.279541015625, theta: tensor([20.0522, -0.6871], requires_grad=True), Gradients: tensor([  -52.1939, -1312.9094])\n",
      "Epoch: 1, Loss: 580.1749877929688, theta: tensor([2.0075e+01, 4.9269e-03], requires_grad=True), Gradients: tensor([ -22.9481, -692.0174])\n",
      "Epoch: 2, Loss: 214.13821411132812, theta: tensor([20.0827,  0.3698], requires_grad=True), Gradients: tensor([  -7.5422, -364.8546])\n",
      "Epoch: 3, Loss: 112.44169616699219, theta: tensor([20.0821,  0.5622], requires_grad=True), Gradients: tensor([   0.5713, -192.4646])\n",
      "Epoch: 4, Loss: 84.138916015625, theta: tensor([20.0773,  0.6639], requires_grad=True), Gradients: tensor([   4.8421, -101.6281])\n",
      "Epoch: 5, Loss: 76.21393585205078, theta: tensor([20.0702,  0.7176], requires_grad=True), Gradients: tensor([  7.0881, -53.7640])\n",
      "Epoch: 6, Loss: 73.94693756103516, theta: tensor([20.0619,  0.7462], requires_grad=True), Gradients: tensor([  8.2673, -28.5431])\n",
      "Epoch: 7, Loss: 73.2509994506836, theta: tensor([20.0530,  0.7614], requires_grad=True), Gradients: tensor([  8.8843, -15.2533])\n",
      "Epoch: 8, Loss: 72.99138641357422, theta: tensor([20.0438,  0.7697], requires_grad=True), Gradients: tensor([ 9.2051, -8.2505])\n",
      "Epoch: 9, Loss: 72.8530502319336, theta: tensor([20.0345,  0.7742], requires_grad=True), Gradients: tensor([ 9.3698, -4.5603])\n",
      "Epoch: 1000, Loss: 32.0439338684082, theta: tensor([13.9094,  1.0674], requires_grad=True), Gradients: tensor([ 3.7133, -0.1750])\n",
      "Epoch: 2000, Loss: 25.875734329223633, theta: tensor([11.5181,  1.1801], requires_grad=True), Gradients: tensor([ 1.4294, -0.0673])\n",
      "Epoch: 3000, Loss: 24.96167755126953, theta: tensor([10.5976,  1.2235], requires_grad=True), Gradients: tensor([ 0.5503, -0.0260])\n",
      "Epoch: 4000, Loss: 24.826221466064453, theta: tensor([10.2433,  1.2402], requires_grad=True), Gradients: tensor([ 0.2118, -0.0100])\n",
      "Epoch: 5000, Loss: 24.806148529052734, theta: tensor([10.1069,  1.2466], requires_grad=True), Gradients: tensor([ 0.0815, -0.0039])\n",
      "Epoch: 6000, Loss: 24.80317497253418, theta: tensor([10.0543,  1.2491], requires_grad=True), Gradients: tensor([ 0.0314, -0.0015])\n",
      "Epoch: 7000, Loss: 24.802734375, theta: tensor([10.0341,  1.2500], requires_grad=True), Gradients: tensor([ 0.0121, -0.0006])\n",
      "Epoch: 8000, Loss: 24.80266761779785, theta: tensor([10.0264,  1.2504], requires_grad=True), Gradients: tensor([ 0.0047, -0.0002])\n",
      "Epoch: 9000, Loss: 24.80265998840332, theta: tensor([10.0234,  1.2505], requires_grad=True), Gradients: tensor([ 1.8253e-03, -9.6262e-05])\n",
      "tensor([10.0222,  1.2506], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "opt_theta = training_loop(n_epochs = 10000,\n",
    "                          learning_rate = 0.001,\n",
    "                          theta = torch.tensor([20.0,-2.0],requires_grad =True),\n",
    "                          XTensor = XTensor,\n",
    "                          rateTensor=rateTensor)\n",
    "print(opt_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a706aae-13ac-47a1-a547-12ea62fbca61",
   "metadata": {},
   "source": [
    "Once again we found our initial parameters.\n",
    "\n",
    "This type of output is very similar to what you see when you train DeepLabCut (more on this next week)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ef3f79-230f-471c-9bff-02f63dc728cd",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* We implemented a linear regression model in python.\n",
    "* We defined a cost function (MSE) to measure how good/bad the model predictions are.\n",
    "* We calculated the partial derivative of the MSE for a set of coefficients.\n",
    "* We wrote a training loop to adjust the coefficients iteratively in order to minimize MSE\n",
    "* We covered 3 possible ways in which you can train models (klearn.linear_model, scipy.optimize.minimize and pytorch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214e269e-2d2d-4dfb-b69d-97c94bfb9741",
   "metadata": {},
   "source": [
    "# Machine learning challenge\n",
    "\n",
    "A new paper comes out on speed cells. The authors suggest that the firing rate of speed cells depends on both speed and acceleration. \n",
    "\n",
    "Two factors are influencing the firing rate of the neuron. \n",
    "\n",
    "You would like to create a linear regression model that predict the firing rate of these cells.\n",
    "\n",
    "Your new model is as follows.\n",
    "\n",
    "$rate = speed*w_1 + acceleration*w_2 + b + error$\n",
    "\n",
    "In this model you will have 3 coefficients, $\\theta_0, \\theta_1, \\theta_2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b3012118-8fd9-4ad4-9b7f-f571b329f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"../data/animal_acceleration.npy\"\n",
    "acceleration = np.load(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b4cd8d44-1d23-4255-a5cf-73b7fd55a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"../data/animal_speed.npy\"\n",
    "speed = np.load(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c4fcde8b-7357-4f1d-81cd-5b69b610b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn =  \"../data/y_rate.npy\"\n",
    "rate = np.load(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfecda7-4dec-4820-a9dd-9ea7dbbd5a85",
   "metadata": {},
   "source": [
    "Do the following steps\n",
    "\n",
    "1. Use scatter plots to check if there is a linear relationship between speed and rate, and between acceleration and rate.\n",
    "2. Create you matrix `theta` with the 3 parameters of your model\n",
    "3. Create your matrix `X` with the speed and acceleration data. Don't forget the first row of ones.\n",
    "4. Train a model to find the best model parameters to predict the firing rate of the neuron. What are these parameters?\n",
    "5. Plot the original data together with the predicted firing rates from your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0739d5f-b127-482e-a9cf-ee050ea2ed09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
