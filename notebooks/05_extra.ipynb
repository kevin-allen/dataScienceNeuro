{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d3f63d-d7b9-4b66-a46a-a3116545bbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "68248543-f302-462e-8a19-b5e885261a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional_model(nn.Module):\n",
    "    \"\"\"\n",
    "    Class to create convolutional neural network.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializer. Runs when an object is created\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        # input images will be batch_size,3,32,32\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels= 12, kernel_size=5,stride=1, padding=0)  # output shape: [batch_size, 6, 28, 28]\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2) # a max poll operation, # output shape: [batch_size, 6, 14,14]\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5,stride=1, padding=0)  # output shape: [batch_size, 16, 10, 10]\n",
    "                                                                                                   # after 2nd pool: [batch_size, 16 , 5, 5]\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = 24 * 5 * 5, out_features=120) # here we need to know the dimension of the data coming in (following second pool operation)\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features =84)\n",
    "        self.fc3 = nn.Linear(in_features = 84, out_features=10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Make predictions with our model\n",
    "        \"\"\"\n",
    "        # input shape [batch,3,32,32]\n",
    "        x = F.relu(self.conv1(x)) # [batch, 6, 28, 28]\n",
    "        x = self.pool(x) # [batch, 6, 14, 14]\n",
    "        \n",
    "        x = F.relu(self.conv2(x)) # [batch, 16, 10, 10]\n",
    "        x = self.pool(x) # [batch, 16, 5, 5]\n",
    "                \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch, needed for the linear layer, [batch, 400]\n",
    "        \n",
    "        x = F.relu(self.fc1(x)) # [batch, 120]\n",
    "        x = F.relu(self.fc2(x)) # [batch, 84]\n",
    "        x = self.fc3(x) # [batch, 10]\n",
    "        return x\n",
    "\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d70a0f4c-c713-475d-a97c-2169c7614dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_conv_model = Convolutional_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "79995821-e1ed-46ff-9517-a7cc2ae9b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(large_conv_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a09e0afd-8334-41c1-81d8-2509f688f40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, batch: 1999 Loss: 2.05265518411994\n",
      "Epoch: 0, batch: 3999 Loss: 1.6668165161013604\n",
      "Epoch: 0, batch: 5999 Loss: 1.5288759690523148\n",
      "Epoch: 0, batch: 7999 Loss: 1.4635652123466134\n",
      "Epoch: 0, batch: 9999 Loss: 1.3846576754078268\n",
      "Epoch: 0, batch: 11999 Loss: 1.3460146833900362\n",
      "Epoch: 1, batch: 1999 Loss: 1.2441345437057316\n",
      "Epoch: 1, batch: 3999 Loss: 1.2110878165960313\n",
      "Epoch: 1, batch: 5999 Loss: 1.2008140398729592\n",
      "Epoch: 1, batch: 7999 Loss: 1.183246555255726\n",
      "Epoch: 1, batch: 9999 Loss: 1.1591811258029192\n",
      "Epoch: 1, batch: 11999 Loss: 1.1121926585584878\n",
      "Epoch: 2, batch: 1999 Loss: 1.0328773553315551\n",
      "Epoch: 2, batch: 3999 Loss: 1.047523371754214\n",
      "Epoch: 2, batch: 5999 Loss: 1.03557501889579\n",
      "Epoch: 2, batch: 7999 Loss: 1.017257530563511\n",
      "Epoch: 2, batch: 9999 Loss: 1.0252421984383837\n",
      "Epoch: 2, batch: 11999 Loss: 1.0108525015797931\n"
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs=3,\n",
    "              optimizer=optimizer,\n",
    "              loss_fn=loss_fn,\n",
    "              model=large_conv_model,\n",
    "             train_dataloader=train_dataloader,\n",
    "             test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "63cd6306-66ba-487e-827d-9f770faad300",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy,_,_ = evaluate_model_accuracy(large_conv_model,train_dataloader)\n",
    "test_accuracy,_,_  = evaluate_model_accuracy(large_conv_model,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "62f6992a-23c7-4c10-99de-3911332bdea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 67.964\n",
      "Accuracy on test set: 63.86\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set:\", train_accuracy)\n",
    "print(\"Accuracy on test set:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
